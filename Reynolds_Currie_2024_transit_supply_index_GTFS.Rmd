---
title: Leveraging GTFS data to calculate an open-source Transit Supply Index
runningheader: "Reynolds and Currie"
author:
  - name: James Reynolds
    note: Corresponding Author
    position: Research Fellow
    email: james.reynolds@monash.edu
    affiliation: Public Transport Research Group, Institute of Transport Studies, Department of Civil Engineering, Monash University, Victoria, Australia
  - name: Graham Currie
  
    position: Professor
    email: graham.currie@monash.edu
    affiliation: Public Transport Research Group, Institute of Transport Studies, Department of Civil Engineering, Monash University, Victoria, Australia
abstract: |
  TBC.
  
keywords: ["Transit", "Public transport", "GTFS", "Benchmarking"]
bibliography: [packages.bib, References.bib]
biblio-style: unsrtnat
classoption:
  - numbered #  When numbered option is activated, lines are numbered.
output: rticles::trb_article
wordcount: 684
---

```{r setup, include = FALSE}
library(tufte)
library(tidyverse)
library(dplyr)
library(tidytransit)
library(sp)
library(absmapsdata)
library(ptinpoly)
library(magrittr)
library(ggplot2)
library(sf)
library(ASGS.foyer)
library(raster)
library(ggmap)
library(units)
library(janitor)
library(mapview)
library(ggstatsplot)
library(gtsummary)
library(moments)
library(scales)
library(gtfstools)
library(lubridate)



knitr::opts_chunk$set(echo = FALSE)
```


# Introduction
Transit service level indicators include those in the Transit Capacity and Quality of Service Manual (TCQSM) [@TCQSM:2013], the Transit Score metric and many more. Practitioners, researchers and advocates seeking to use such metrics may face two inter-related challenges: firstly, there is the problem of calculating the metrics themselves for a specific location; secondly, is the challenge of explaining the metrics, their meaning and importance those who are not specialists in transit, such as politicians, other decision-makers or the general public. 

The TCQSM specifies Levels of Service (LOS) between A and F across a range of factors including service span, frequency, speed, and the proportion of population serviced. Previous research by @Wong:2013aa overcame some challenges of using the TCQSM, by using Python, PostgreSQL and R software and GTFS feeds as input to automate the calculation of daily average headways, route length and stop numbers. This indicators, however, are route based and so do not include any consideration of geographic or population coverage. Further metrics addressing these topics and much detail about their calculation and meaning are included in the TCQSM, such as the Service Coverage Area (pp. 5-8 to 5-21). However, these appear highly detailed, may required bespoke GIS or other analysis, and it might be challenging to explain these measures (beyond the fact at A is good and F is bad) to non-technical decision-makers, stakeholders or others who might be involved. Transit Score provides a similarly easily understood rating scale, scoring locations out of 100 [@WalkScore:2023tg]. However, the algorithm is patented and effectively a black box, meaning that it is not possible to calculate scores independently to understand how the metric might change with cahnges to the transit system or surrounding environment. 

The Supply Index developed by @currie2007identifying may provide a metric that is relatively easy to calculate, open (rather than a black box), and relatively simple for a non-technical audience to understand, engage with and use. This Index is based on calculating the number of transit arrivals at stops within an area of interest, with an adjustment made for the amount of the area of interest that is within a typical walk access distance of each stop.  However, it does not appear to have been widely used, perhaps in part because it still required an analyst to obtain sources of timetable and geographic data. Since the publication of @currie2007identifying such data has become much easier to obtain with more than 10,000 agencies now providing timetable and network data using the General Transit Feed Specification (GTFS) format [@GTFS]. A gap, however, is that there is not yet a method for calculating the @currie2007identifying Supply Index directly from GTFS data. 

This paper reports the development of R code to calculate the Supply Index of @currie2007identifying directly from GTFS data. The code is developed using data from a single case: the GTFS for Victoria in Australia, which includes Greater Melbourne. Cross-case comparison to Toronto, Canada, and Washington DC, USA, is also undertaken to test the results and gain understanding of how the Supply Index might be useful for practitioners, researchers and advocates. The motivation for this research is to better understand how GTFS data might be used to produce benchmarking metrics that can be calculated using open-source code, that can be used to access proposed network changes and which may be relatively easy for non-technical specialists to understand. 

# Research context
Even a brief search shows that there is a very large number of metrics available for benchmarking transit services, for example: the Transit Cooperative Research Program (TCRP) Report 88 provides an extensive guidebook on developing a performance-measurement system [@Ryus:2003aa]; online databases are provided by the Florida Transit Information System (FTIS) [@Florida-Transit-Information-System:2018aa] and the International Association of Public Transport (UITP) [@UITP:2015aa] have online databases, while the Transport Strategy Centre of Imperial College London runs extensive annual benchmarking programmes across over 100 transit provides around the world [@Imperial-College-London:2023aa]. The Fielding Triangle [@FieldingGordonJ1987Mpts] provides a framework for understanding how such metrics combine service inputs, service outputs and service consumption to describe cost efficiency, cost effectiveness or service effectiveness measures. At a larger scale, @Litman:2003ab and @Litman:2016aa discuss some of the traffic, mobility, accessibility, social equity, strategic planning and other rational decision-making frames that might underlie such transit metrics, while @Reynolds:2017ah extends this into models of how institutionalism, incrementalism and other public policy models might apply to decision-making processes. Further examples are provided by @GuzmanLuisA.2017Aeit, who develop a measure of accessibility in the context of policy development and social equity for Latin American Bus Rapid Transit (BRT) based networks,  and the street space allocation metrics based around 10 ethical principles from @Creutzig2020streetspaceallocation. 

However, many of these metrics are difficult to calculate, complex to explain or understand, and likely not well suited to communication with those who are not transit planners or engineers, or otherwise technical specialists. However, where pre-calculated metrics are immediately available it may not be possible for  generate metrics for proposed system changes or know exactly how scores are calculated. The TCQSM and Transit Score may provide contrasting examples:  with respect to the first challenge, TCQSM metrics may require large amounts of network, service, population and other data to be assembled before the  indicators can be calculated; whereas Transit Scores are readily available on the @WalkScore:2023tg website for locations with a published GTFS feed  (eliminating the need for any calculations). With respect to the second challenge,  the meaning of the Transit Score appears easy to explain (the closer to 100, the better), but as the score is calculated by a patented algorithm (effectively a black-box) it may not be easy to understand or explain the connection between real-world conditions and the score, or what might need to be done to improve the score and service levels. Nor does it appear to be possible for Transit Scores to be generated for proposed changes to networks. The TCQSM, in contrast is open-source, in that @TCQSM:2013 provide a manual describing all the metrics and how to calculate them.  However, the calculations themselves appear to be complex, which may be a barrier to use by practitioners, researchers, advocates or others who are not transit scheduling specialists. While @Wong:2013aa provides open-source code (https://github.com/jcwong86/GTFS_Explore_Tool) this is 11 years old and does not appear to be currently maintained. Future research may involve reviewing this code and using it to analyse modern GTFS feeds. However, in this paper the aim is more modest, in that the objective is to develop code to calculate the simpler Suppy Index metric from @currie2007identifying.  


## The Suppy Index
The Supply Index is shown in Equation \ref{eq:supply_index}. Minor adjustments have been made to generalise the equation, as @currie2007identifying focused on the context of Melbourne's Census Collection Districts (CCD) and calculations based on a week of transit service. 
\begin{equation}
\label{eq:supply_index}
  SI_{area, time} = \sum{\frac{Area_{Bn}}{Area_{area}}*SL_{n, time}}
\end{equation}

 


$SI_{area, time}$ is the Supply Index for the area of interest and a given period of time. $Area_{Bn}$ is the buffer area for each stop (n) within the area of interest. In  @currie2007identifying this was based on a radius of 400 metres for bus and tram stops, and 800 metres for railway stations. $Area_area$ is the area of the area of interest, and $SL_{n,time}$ is the number of transit arrivals for each stop for a given time period.  



An advantage of the Supply Index is that it is a relatively simple number to calculate, understand and explain. It describes the number of transit arrivals at stops within an area of interest and time frame, multiplied by a factor accounting for the proportion of the area of interest that is within typical walking distance of each stop. Hence, more services, more stops and higher frequencies would all result in an increase in Supply Index score. The Supply Index, however, does not incorporate further aspects, such as service span,  off-peak share of service or service speed. However, including such metrics may increase the complexity of calculating and describing the index to non-transit specialists. Such simplicity is helped by the way that the Index is additive, in that SI~area, time~ scores can be aggregated to calculate an overall score across multiple time periods or for a region encompassing multiple areas of interest. 

@currie2007identifying calculated the SI~area, time~  for various CCDs in Melbourne using a timetable database provided by the Victorian Public Transport Authority (PTA). This predated the widespread availability of GTFS data, which provides a standardised format for timetable data that is produced by many transit systems. GTFS is an open, text-based format that was developed originally to allow transit information to be included in the Google Maps navigation platform [@GTFS]. A question, therefore, is how to calculate the SI using GTFS data so that SI~areas~ can be calculated and compared for any area of interest where transit service information is available in the GFTS format. 

# Methodology
This study adopts a case research approach by developing code to calculate Supply Indexes for Melbourne (Australia), Toronto (Canada) and Washington D.C. (USA). These three cases were selected as they are familiar to the researchers, and as there is likely to be enough variety in how the GTFS feeds, potential areas of interest and other aspects are set up such that the developed code will be generalis-able to other places.  Additionally, the case selection continues the long-standing practice of comparing Melbourne and Toronto, as well as grounding one of the three cases in the context of the transit system where the Transportation Research Board Annual Meeting is located.  

Various analysis tools are available that make us of GTFS data, including the tidytransit package [@tidytransit2023] for the R statistical programming language [@R-base]. @tidytransit_departure_timetable provides code to calculate a departure timetable from a GTFS feed, and this was adapted to calculate arrivals at a stop and the SL~Bn~ term. 


```{r arrival_timetable_as_a_function, echo=FALSE, cache=TRUE}

#This was code was developed for another project (https://github.com/James-Reynolds/DEAKIN-housing-and-transit-accessibility),  based on the tidytransit vignette on producing a departure timetable (@tidytransit_departure_timetable.  There is back history availlble at at that github repository  for further details, but basically I wrote a departure_timetable_function and fixed up a bit where it wasn't accounting for through-running services.  This was then directly adjusted to create an arrival_timetable function (below) --- However, I did not adjust all the variable names in the function to reflect that it is about arrivals, not departures. 
#---also, something broke in the first few lines where it adds the trip_origins to the gtfs$trips data.  Not quite sure what broke, but the first 15 lines of the below function fixes it. 

library(tidytransit)
#gtfs <- read_gtfs("data/1google_transit.zip")
#stop_to_show <- "Wallan Railway Station (Wallan)"
#date_to_show <- "2023-04-27"

arrival_timetable_function <- function(gtfs, stop_to_show, date_to_show){
  # get the id of the first stop in the trip's stop sequence

  first_stop_id <- gtfs$stop_times %>% 
    group_by(trip_id) 

  first_stop_id <- first_stop_id %>%
      filter(stop_sequence == which.min(stop_sequence)) %>%
      summarise(trip_id, stop_id)

  # join with the stops table to get the stop_name
  first_stop_names <- left_join(first_stop_id, gtfs$stops, by="stop_id")

  # rename the first stop_name as trip_origin
  trip_origins <- first_stop_names %>% select(trip_id, trip_origin = stop_name)

  # join the trip origins back onto the trips
  gtfs$trips <- left_join(gtfs$trips, trip_origins, by = "trip_id")
  
  #### get the id of the last stop in the trip's stop sequence
  last_stop_id <- gtfs$stop_times %>% 
    group_by(trip_id) %>% 
    summarise(stop_id = stop_id[which.max(stop_sequence)])

  # join with the stops table to get the stop_name
  last_stop_names <- left_join(last_stop_id, gtfs$stops, by="stop_id")

  # rename the last stop_name as trip_destination
  trip_destinations <- last_stop_names %>% dplyr::select(trip_id, trip_destination = stop_name)

  # join the trip destinations back onto the trips
  gtfs$trips <- left_join(gtfs$trips, trip_destinations, by = "trip_id")

  
  #gtfs$trips %>%
  #  dplyr::select(route_id, trip_origin) %>%
  #  head()

  if(!exists("trip_headsign", where = gtfs$trips)) {
    # get the last id of the trip's stop sequence
    trip_headsigns <- gtfs$stop_times %>% 
      group_by(trip_id) %>% 
      summarise(stop_id = stop_id[which.max(stop_sequence)]) %>% 
      left_join(gtfs$stops, by="stop_id") %>% dplyr::select(trip_id, trip_headsign.computed = stop_name)

  #create a new field with 
  trip_destination <- gtfs$stop_times %>% 
      group_by(trip_id) %>% 
      summarise(stop_id = stop_id[which.max(stop_sequence)]) %>% 
      left_join(gtfs$stops, by="stop_id") %>% dplyr::select(trip_id, trip_headsign.computed = stop_name)

    
    
    # assign the headsign to the gtfs object 
    gtfs$trips <- left_join(gtfs$trips, trip_headsigns, by = "trip_id")
  }

  stop_ids <- gtfs$stops %>% 
    filter(stop_name == stop_to_show) %>% 
    dplyr::select(stop_id)

  departures <- stop_ids %>% 
    inner_join(gtfs$stop_times %>% 
                 dplyr::select(trip_id, arrival_time, 
                        departure_time, stop_id), 
               by = "stop_id")
  
  departures <- departures %>% 
    left_join(gtfs$trips %>% 
                dplyr::select(trip_id, route_id, 
                       service_id, trip_headsign, 
                       trip_origin, 
                       trip_destination), 
              by = "trip_id") 
  
  departures <- departures %>% 
    left_join(gtfs$routes %>% 
                dplyr::select(route_id, 
                       route_short_name), 
              by = "route_id")

  #remove trips where first stop is equal to the stop_to_show, as these stops originate at this stop and so do not depart
  departures <- departures %>% 
      filter(trip_origin != stop_to_show)
  
  
  #departures %>% 
  #  dplyr::select(arrival_time,
  #         departure_time,
  #         trip_headsign,trip_origin,
  #         route_id) %>%
  #  head() %>%
  #  knitr::kable()

  #head(gtfs$.$dates_services)


  services_on_180823 <- gtfs$.$dates_services %>% 
    filter(date == date_to_show) %>% dplyr::select(service_id)

  departures_180823 <- departures %>% 
    inner_join(services_on_180823, by = "service_id")

#  departures_180823 %>%
 #   arrange(departure_time, stop_id, route_short_name) %>% 
  #  dplyr::select(departure_time, stop_id, route_short_name, trip_headsign) %>% 
   # filter(departure_time >= hms::hms(hours = 7)) %>% 
   # filter(departure_time < hms::hms(hours = 7, minutes = 10)) %>% 
  #  knitr::kable()

  route_colors <- gtfs$routes %>% dplyr::select(route_id, route_short_name, route_color)
  route_colors$route_color[which(route_colors$route_color == "")] <- "454545"
  route_colors <- setNames(paste0("#", route_colors$route_color), route_colors$route_short_name)

  #No need for list of outputs anymore, as the graphs are no longer needed
  #output <- list(
   #   ggplot(departures_180823) + theme_bw() +
    #  geom_point(aes(y=trip_origin, x=arrival_time, color = route_short_name), size = 0.2) +
     # scale_x_time(breaks = seq(0, max(as.numeric(departures$departure_time)), 3600), 
      #             labels = scales::time_format("%H:%M")) +
      #theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      #theme(legend.position = "bottom") +
      #scale_color_manual(values = route_colors) 
  #    labs(title = paste("Departures from", stop_to_show, "on", date_to_show))
  #add a return value to provide the number of services shown in the graph as an output
       #   , nrow(departures_180823)
    #  )
  #return list with graph and the number of services. 
  return(departures_180823)
  
}
#arrivals_southern_cross_230427 <- arrival_timetable_function(gtfs=mel1, stop_to_show="Southern Cross Railway Station (Melbourne City)", date_to_show="2023-04-27")
#head(arrivals_southern_cross_230427)
```



The gtfstools R package [@R-gtfstools] was used to split input GTFS feeds by mode to facilitate the buffer zone calculation.  Buffer zones of 400 metres for bus and Light Rail Transit (LRT) services and 800 metres for heavy rail, as per @currie2007identifying. There is an extended mode definition that includes modes beyond the 10 in the GTFS standard [@filter_GTFS_by_mode], but these are not dealt with by the gtfstools package. Further research may seek to extend this such that other modes can be included, but for the purposes of this study the buffer zone was set at 400 metres for cable trams, aerial lifts such a gondalas and trolleybuses, and at 800 metres for ferries, funiculars and monorails.  

```{r read_buffer_zone, echo=FALSE}

buffer_zone_definitions <- as_tibble(read.csv ("buffer_zones.csv"))

class(buffer_zone_definitions$code) <- "character"
buffer_zone_definitions$mode <- noquote(buffer_zone_definitions$mode)
buffer_zone_definitions$description_examples <- noquote(buffer_zone_definitions$description_examples)
class(buffer_zone_definitions$mode) <- "character"
class(buffer_zone_definitions$description_examples) <- "character"
#set buffer zone units to metres
buffer_zone_definitions$buffer <- as_units(buffer_zone_definitions$buffer, "m")

```

```{r split_gtfs_function, echo=FALSE}

split_gtfs_into_modes_and_put_in_list <- function(gtfs){ 
  gtfs_LRT <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 0))
  gtfs_subway <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 1))
  gtfs_rail <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 2))
  gtfs_bus <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 3))
  gtfs_ferry <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 4))
  gtfs_cable_tram <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 5))
  gtfs_aerial_lift <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 6))
  gtfs_funicular <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 7))
  gtfs_trolleybus <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 11))
  gtfs_monorail <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 12))
 

  gtfs_into_modes_and_put_in_list <- list(
    LRT = gtfs_LRT, 
    subway = gtfs_subway,
    rail = gtfs_rail,
    bus = gtfs_bus,
    ferry = gtfs_ferry, 
    cable_tram = gtfs_cable_tram, 
    aerial_lift = gtfs_aerial_lift, 
    funicular = gtfs_funicular, 
    trolleybus = gtfs_trolleybus,
    monorail = gtfs_monorail 
  )

  return(gtfs_into_modes_and_put_in_list)
}

```

Where transit stops are located close to boundaries their catchment areas may fall into multiple areas of interest. The sp package from [@spatial_data_in_R, @applied_spatial_data_analysis_with_R] provides tools for manipulating geographic data and shape files in R. This is used to calculate the proportion of each stop's catchment area that falls into each geographical area of interest. GTFS files define stop locations based on latitude and longitude [@GTFS_schedule_reference], whereas the Area~Bn~ calculation needs to be provided in the same units as the Area~area~ variable. This therefore necessitates the use of a geographic transform so that calculations can be undertaken in metres.   


```{r load_abs_data, messages = FALSE, warnings = FALSE, echo=FALSE, fig.fullwidth=TRUE, fig.cap="Melbourne SA1 map"}
#Load SA1 data
sa1_map_data <- sa12021

##Map Greater Melbourne SA1 areas
#map <- sa1_map_data %>%
#  filter(gcc_name_2021 == "Greater Melbourne") %>%   # let's just look Melbourne
#  ggplot() +
#  geom_sf(aes(geometry = geometry,  # use the geometry variable
#              fill = areasqkm_2021),     # fill by area size
#          lwd = 0,                  # remove borders
#          show.legend = TRUE) +    # keep legend
# # geom_point(aes(cent_long,
#  #               cent_lat),        # use the centroid long (x) and lats (y)
#   #          colour = "white") +    # make the points white
#  theme_void() +                    # clears other plot elements
#  coord_sf()

#map

p <- sa1_map_data
p <- p %>% 
  dplyr::mutate(area = st_area(p))
units(p$area) <- as_units("m^2")




```

The SI~area~ was calculated on a mode-by-mode and stop-by-stop basis, by first determining the amount of the catchment area (Area~Bn~) that falls into each geographical area of interest for the stop in question. This is combined with the area for each geographical area of interest (Area~area~) and the number of stop arrivals within the (SL~Bn~) to calculate the contribution to the index scores made by just that single stop for every area of interest (the SI~area, time, mode, n~); these are then added to a cumulative total field for each area of interest; and the calculations are repeated until all stops and modes in the GTFS file have been included. 


```{r SICCD_calc_as_functions, echo=FALSE, warning=FALSE, message=FALSE}

###Temporary variables to help with writing the function
#areas_of_interest <- sa1_map_data %>%
#  filter(gcc_name_2021 == "Greater Melbourne") 
#mel3 <- read_gtfs("data/3google_transit.zip")
#mel3_list_by_mode <- split_gtfs_into_modes_and_put_in_list(mel3)
#gtfs_list_by_mode <- mel3_list_by_mode
#start_date = "2023-04-27"
#period_in_days = 2
#EPSG_for_transform = 28355
#areas_of_interest_id_field = "sa1_code_2021"

#### The function ________
SI_calc_function <- function(areas_of_interest = areas_of_interest, areas_of_interest_id_field = areas_of_interest_id_field, gtfs_list_by_mode = gtfs_list_by_mode, start_date = start_date, period_in_days = period_in_days, EPSG_for_transform = EPSG_for_transform){

  ##Initialise variables used in function
  #the top level list. First element is a tibble of areas_of_interest_id_field. The remainder of the list has one element for each day of analysis, with each element containing a tibble with the SI scores for each mode.   
  SI_list_by_date_and_mode <- list((tibble(areas_of_interest %>% select(as.character(areas_of_interest_id_field))) %>% select(!"geometry")))
  names(SI_list_by_date_and_mode) <- as.character(areas_of_interest_id_field)

  # convert to sf format and project
  areas_of_interest_sf <- areas_of_interest %>%
  # convert to simple features
  sf::st_as_sf() %>%
    st_transform(crs = EPSG_for_transform) 
  # add Area_area value to areas_of_interest_sf 
  areas_of_interest_sf <- areas_of_interest_sf %>% 
    dplyr::mutate(Area_area = st_area(areas_of_interest_sf))
  # Add SI column to areas_of_interest_sf
  areas_of_interest_sf <- areas_of_interest_sf %>% 
    dplyr::mutate(SI = 0)
    
#2-level list to put the SI results in, with each element representing one of the days that is being analysed. 
    # This becomes a list (of lists), with one element for each mode for the day_of_analysis in question (j)
    SI_for_day_of_analysis_list_by_mode <- list()
  
  #for loop that drives the first level of the list, recording the day of analysis
  for (j in seq(1, period_in_days, 1)) {
    
    ##Initialise variables used in first level of the list
    day_of_analysis = as.character(ymd(start_date) - days(1) + days(j))
    
    #dataframe to store the SIs for each area of interest by mode for day j
       SI_for_day_of_analysis_by_mode_k <- (tibble(areas_of_interest %>% select(as.character(areas_of_interest_id_field))) %>% select(!"geometry"))
    
    ##for loop that drives the second level of the list, recording SI by mode
      for (k in seq(1, length(names(gtfs_list_by_mode)), 1)){   
        #look up the buffer distance for mode k
        buffer_distance <- buffer_zone_definitions %>% filter(short_name == as.character(names(gtfs_list_by_mode[k]))) %>% select(buffer) %>% as.numeric()
     
        #add zero-ed column to store SIs for mode k
        SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k %>% tibble::add_column(a = 0)
        #change name of added column to match mode k
names(SI_for_day_of_analysis_by_mode_k) <- c( names(SI_for_day_of_analysis_by_mode_k[,1:ncol(SI_for_day_of_analysis_by_mode_k)-1]), eval(names(gtfs_list_by_mode[k])))                         
        
        #check if the gtfs mode in question has any stops - many of the modes (e.g. Monorail) will typically have zero services or stops.  If the mode in question (k) does not have any stops, then there is no further calculation required, and the existing column of zeros can be left as is. 
        if(nrow(gtfs_list_by_mode[[as.character(names(gtfs_list_by_mode[k]))]][["stops"]]) > 0) { 
         SI_return_value_for_that_mode <- rep(0,nrow(areas_of_interest))
         #which is calculated in the following for loop, which passes over all of the stops in the gtfs file for the mode in question
          for (i in seq(1, nrow(gtfs_list_by_mode[[ as.character(names(gtfs_list_by_mode[k]))]][["stops"]]), 1)) {
      
            #create dataframe with stop i lat and lon value
            dat_sim <- data.frame(lat = gtfs_list_by_mode[[as.character(names(gtfs_list_by_mode[k]))]][["stops"]]$stop_lat[i],
            long = gtfs_list_by_mode[[as.character(names(gtfs_list_by_mode[k]))]][["stops"]]$stop_lon[i])
            # Convert that dataframe (with stop i latitude and longitude) into a sf object, with the crs set to EPSG:4326 (which is the CRS for lat/long values), 
           # and then transform to be expressed as per the EPSG that is being used for the analysis (ie. shift to metres)
            dat_sf <- st_as_sf(dat_sim, coords = c("long", "lat"), crs = 4326) %>% 
            st_transform(crs = EPSG_for_transform)
  
            # make a circle with the buffer distance as the radius around stop i    
            dat_circles <- st_buffer(dat_sf, dist = buffer_distance)
            # Intersect the circle with the polygons
            int_circles <- st_intersection(areas_of_interest_sf, dat_circles)

            ##TEST CODE Map to check that it is working the way it is expect to.
            #map <- int_circles %>%
              #ggplot() +
              #geom_sf(aes(geometry = geometry,  # use the geometry variable
                  #fill = eval(parse(text=areas_of_interest_id_field))),     # fill by SA1_code
                #lwd = 0,                  # remove borders
                #show.legend = TRUE) +    # keep legend
              #theme_void() +                    # clears other plot elements
              #coord_sf()
              
            #map

            #calculate Area Bn 
            int_circles$area_bn <- st_area(int_circles)
            
            #drop_geometry
            int_circles <- as.tibble(int_circles[, !(colnames(int_circles) %in% "geometry")])
  
            ##Retrieve number of arrivals for that mode and day by...
            #first moving the gtfs for that mode out of gtfs_list_by_mode
            gtfs_k <- as_tidygtfs(eval(parse(text = paste("gtfs_list_by_mode$",names(gtfs_list_by_mode)[k],sep = ""))))
            # then add the number of arrivals at stop i to all rows of the int_circles dataframe. 
            int_circles$SL_Bn <- rep(
              nrow(arrival_timetable_function(gtfs = gtfs_k, stop_to_show = gtfs_list_by_mode[[
                as.character(names(gtfs_list_by_mode[k]))]]$stops$stop_name[i], date_to_show = day_of_analysis)), 
              nrow(int_circles))
    
            #Calculate SI for stop i and drop units
            int_circles$add_to_SI <- as.numeric(int_circles$area_bn / int_circles$Area_area * int_circles$SL_Bn)
  
            
            #Create ordinary tibble with Area of Interest identification code and SIs from stop i to add to the running totals
            export_to_SI_for_day_of_analysis_by_mode_k <- int_circles %>% select(c(as.character(areas_of_interest_id_field), add_to_SI)) 
            
            #drop add_SI column from dataframe reporting SI_by_mode scores up to the date loop (SI_for_day_of_analysis_by_mode_k)
            SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k[, !(colnames(SI_for_day_of_analysis_by_mode_k) %in% "add_to_SI")]
  
            #merge based on eval(parse(text=areas_of_interest_id_field))
            SI_for_day_of_analysis_by_mode_k <- left_join(SI_for_day_of_analysis_by_mode_k, export_to_SI_for_day_of_analysis_by_mode_k)
  
            #convert add_to_SI to non-unit numbers
            SI_for_day_of_analysis_by_mode_k$add_to_SI <- as.vector(SI_for_day_of_analysis_by_mode_k$add_to_SI)
  
            #replace NA with 0 
            SI_for_day_of_analysis_by_mode_k[is.na(SI_for_day_of_analysis_by_mode_k)] = 0
  
            #add the SIs for stop i to the running total of SI for the mode in question
            SI_for_day_of_analysis_by_mode_k[,eval(names(gtfs_list_by_mode[k]))] <- SI_for_day_of_analysis_by_mode_k[,eval(names(gtfs_list_by_mode[k]))] + SI_for_day_of_analysis_by_mode_k$add_to_SI
          
            #close (i) loop for calculating SIs for stop i and adding to the running total of SI
            }
        
        #close the if(no stops in gtfs for that mode) test 
        }
       
       #close for (k) loop for calculating SI for a single mode on a single day
      }  
       
      #drop area of interest id code from dataframe of SI by mode for the day of analysis
      SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k[,2:ncol(SI_for_day_of_analysis_by_mode_k)]
      
      #drop add_to_SI column from dataframe of SI by mode for the day of analysis
      SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k[,!names(SI_for_day_of_analysis_by_mode_k) %in% "add_to_SI"]
       
            #add new element to the list_by_date for the date_of_analysis
      SI_list_by_date_and_mode <- append(SI_list_by_date_and_mode, list(SI_for_day_of_analysis_by_mode_k), after = length(SI_list_by_date_and_mode))
    
      #update name of new element to match date
      names(SI_list_by_date_and_mode) <- c(names(SI_list_by_date_and_mode)[1:length(names(SI_list_by_date_and_mode))-1], as.character(day_of_analysis))

    #close for (j) loop for creating the list of days
    }        

 return(SI_list_by_date_and_mode)    

#close function     
}
  


#function to combine all days together. Outputs a dataframe with a row for each area_of_interest and a column for each mode
convert_SI_list_by_date_and_mode_to_SI_df_by_mode.function <- function(SI_list_by_date_and_mode = SI_list_by_date_and_mode) {
  SI_df_by_mode <- SI_list_by_date_and_mode[2:length(names(SI_list_by_date_and_mode))] %>%
  map_dfr(~setNames(.x, paste0("A", 1:ncol(.x))), .id = "Group") %>%
  group_by(Group) %>%
  mutate(ID = 1:n()) %>%
  group_by(ID) %>%
  summarize(across(-Group, .fns = sum, na.rm = TRUE)) %>%
  select(-ID)

  #update column names to match modes
  names(SI_df_by_mode) <- colnames(SI_list_by_date_and_mode[[2]])
  
  #add back area_of_interest_id_ column
  SI_df_by_mode <- cbind(SI_list_by_date_and_mode[1], SI_df_by_mode)
  
  return(SI_df_by_mode)
}



```

# Results

The code is available at https://github.com/James-Reynolds/Transit_Supply_Index_GTFS as an Rmarkdown file (used to typeset this paper). The following subsections discuss the resutls of cases studies used to develop and test the code. 


## Melbourne

Melbourne's GTFS feed is published by Public Transport Victoria (PTV). There are over 400 feeds available on the transitfeeds.com website, with the first dating from March 2015 

The EPSG:28355 transform [@EPSG_28355] was used to shift longitude and latitude into metres as per the Geocentric Datum of Australia 1994 (GDA95 / MGA zone 55) coordinates,

<!---
```{r load_abs_data_results, messages = FALSE, warnings = FALSE, echo=FALSE, fig.fullwidth=TRUE, fig.cap="Melbourne SA1 map"}
#Load SA1 data
sa1_map_data <- sa12021

##Map Greater Melbourne SA1 areas
#map <- sa1_map_data %>%
#  filter(gcc_name_2021 == "Greater Melbourne") %>%   # let's just look Melbourne
#  ggplot() +
#  geom_sf(aes(geometry = geometry,  # use the geometry variable
#              fill = areasqkm_2021),     # fill by area size
#          lwd = 0,                  # remove borders
#          show.legend = TRUE) +    # keep legend
# # geom_point(aes(cent_long,
#  #               cent_lat),        # use the centroid long (x) and lats (y)
#   #          colour = "white") +    # make the points white
#  theme_void() +                    # clears other plot elements
#  coord_sf()

#map
```

--->

Overall

Wheelchair accessibility?

The metro tunnel - adding services

### Toronto

### Washington DC

### Cross-case comparison


# Discussion



# Conclusions



# Author Contribution Statement

The authors confirm contribution to the paper as follows: study conception and
design: A. Anonymous, D. Zoolander; data collection: B. Security; analysis and
interpretation of results: A. Anonymous, B. Security; draft manuscript
preparation: A. Anonymous. All authors reviewed the results and approved
the final version of the manuscript.

# Acknowledgements
This document was prepared using the `rticles` template, created by Gregory Macfarlane, which is based on the \LaTeX originally posted by David Pritchard in 2009 and updated it in 2011, soon after TRB began allowing PDF submissions. Gregory Macfarlane and Ross Wang made adjustments to the template, and Ross Wang now maintains the \LaTeX template at <https://github.com/chiehrosswang/TRB_LaTeX_tex>. Gregory Macfarlane created the `rticles` template in 2021.


# References {#references }

```{r, include=FALSE}
knitr::write_bib(file = 'packages.bib')
```


