---
title: "Transit Supply Index scores on the days of the 2016 and 2021 censuses: using Statistical Area Level 1 (SA1) 2016 boundaries"
runningheader: "Reynolds and Currie" # only for pdf output
author: "James Reynolds and Graham Currie"
date: "`r Sys.Date()`"
output:
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: [packages.bib, References.bib]
link-citations: yes
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}
    \includegraphics[width=2in,height=2in]{ptrg-logo-s.png}\LARGE\\}
  - \posttitle{\end{center}}
---

```{r setup, include=FALSE}
library(tufte)

library(tidyverse)
library(tidytransit)
library(sp)
library(absmapsdata)
library(ptinpoly)
library(magrittr)
library(ggplot2)
library(sf)
library(ASGS.foyer)
library(raster)
library(ggmap)
library(units)
library(janitor)
library(mapview)
library(ggstatsplot)
library(gtsummary)
library(moments)
library(scales)
library(gtfstools)
library(lubridate)
library(kableExtra)
library(knitr)
library(readxl)
library(dplyr)
library(rvest)

# invalidate cache when the tufte version changes
#knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
```

# Introduction

Previous research by @currie2007identifying developed a transit Supply Index (SI), based on calculating the number of transit arrivals at stops within an area of interest, adjusted to account for the typical walk-access catchment for each stop. The Public Transport Research Group (PTRG) has been developing R code to calculate this Supply Index directly from GTFS data. This document describes how the code has been used to output SI scores for the day of the 2016 census and the day of the 2021 census for each of the Australian Bureau of Statistics (ABS) 2016 Statistical Area Level 1 (SA1) zones in Victoria^[These scores have been requested by Maryam Jafari as an input to her PhD project.]. It also presents verification checks to determine the accuracy of the output scores, and shows some statistical analysis of the scores as a way of exploring the output. 

This rest of this document is structured as follows: the next section discusses the research context of the Supply Index. In the third section the methodology for the code development is outlined, including discussion of the case study GTFS for Victoria, Australia, that was used to test and verify the code output. In the fourth section results are presented, starting with verification of the code output through hand-calculation of SI scores for Statistical Area 1 (SA1) areas in the Victorian Alps and Talbot. SI scores for SA1s across the Clayton Statistical Area Level 2 (SA2) zone and the Melbourne City Statistical Area Level 3 (SA3) zones are also examined, followed by a review of the SI scores for SA1s across all of Greater Melbourne and all of Victoria. Mode-by-mode SI scores are also explored, followed by an examination of needs-gaps across the ABS Index for Relative Socio-Economic Advantage/Disadvantage (IRSAD) scores, ranks and population levels. The document then closes with a brief discussion and conclusion section.

# Research context

## The Suppy Index

```{marginfigure}
\begin{equation}
\label{eq:supply_index}
SI_{area, time} = \sum{\frac{Area_{Bn}}{Area_{area}}*SL_{n, time}}
\end{equation}
```

Equation \ref{eq:supply_index}^[In Equation \ref{eq:supply_index} $SI_{area, time}$ is the Supply Index for the area of interest and a given period of time. $Area_{Bn}$ is the buffer area for each stop (n) within the area of interest. In @currie2007identifying this was based on a radius of 400 metres for bus and tram stops, and 800 metres for railway stations. $Area_area$ is the area of the area of interest, and $SL_{n,time}$ is the number of transit arrivals for each stop for a given time period.
] shows the Supply Index^[Minor adjustments have been made to generalise the equation, as @currie2007identifying focused on the context of Melbourne's Census Collection Districts (CCD) and calculations based on a week of transit service.]. An advantage of the Supply Index is that it is a relatively simple number to calculate, understand and explain. It describes the number of transit arrivals at stops within an area of interest and time frame, multiplied by a factor accounting for the proportion of the area of interest that is within typical walking distance of each stop. Hence, more services, more stops and higher frequencies would all result in an increase in Supply Index score. 

The Supply Index does not incorporate further aspects, such as service span, off-peak share of service or service speed, which are a feature of the Transit Capaicity and Quality of Service Manual (TCQSM) [@TCQSM:2013] and other transit supply metrics. However, including such factirs may increase the complexity of calculating and describing the index to non-transit specialists. 

Simplicity is also helped by the way that the SI is additive. Hence, $SI_{area, time}$ scores can be aggregated to calculate an overall score across multiple time periods or for a region encompassing multiple areas of interest.


@currie2007identifying calculated the $SI_{area, time}$ for various Census Collection Districts (CCDs)^[CCDs predate the introduction of Statistical Areas 1, 2, 3, and 4 (SA1, SA2, SA3, SA4), and other geographical divisions currently used by the Australian Bureau of Statistics (ABS), which may be more familiar to readers.] in Melbourne using a timetable database provided by the Victorian Public Transport Authority (PTA). This predated the widespread availability of GTFS data. A question, therefore, is how to calculate the SI using GTFS data so that $SI_{area, time}$ scores can be calculated and compared for any area of interest where transit service information is available in that format.

## Transport Needs Index(es)

@currie2007identifying also developed a Transport Needs Index based around population, transport and employment data. This was combined with the ABS' Index for Relative Socio-Economic Advantage/Disadvantage (IRSAD) to produce a combined index addressing social and transport needs. This was then used to assess the gap between transit needs and supply. 

Later in this document a similar needs-gap analysis is presented for Victorian SA1s. However, in the needs-gap analysis here only the IRSAD scores and population data are reported. Calculating the combined Transport Needs index as per @currie2007identifying may be a direction for future research.



# Methodology

This document has been prepared using Rmarkdown, which allows the intermingling of written text, code segments and code outputs. Code segments developed in this research are shown in the following, together with the relevant descriptive text^[The Rmarkdown file is available at https://github.com/James-Reynolds/Transit_Supply_Index_GTFS/tree/SA12016_analysis and this can be read in a plain-text editor to view the code snippets themselves. If you are reading this in a PDF document you are seeing just the descriptive text, and outputs from the code where it has been run to produce maps, charts etc.]. This specific document is part of a branch of the developed code, specifically created for reporting the calculation of the SI scores for the SA12016 zones.

Various analysis tools are available that make use of GTFS data, including the tidytransit package [@R-tidytransit] for the R statistical programming language [@R-base]. @tidytransit_departure_timetable provides code to calculate a departure timetable from a GTFS feed, and this was adapted to calculate arrivals at a stop and the SL~Bn~ term in the @currie2007identifying SI equation.

```{r arrival_timetable_as_a_function, echo=FALSE, cache=TRUE}

#This was code was developed for another project (https://github.com/James-Reynolds/DEAKIN-housing-and-transit-accessibility),  based on the tidytransit vignette on producing a departure timetable (@tidytransit_departure_timetable.  There is back history availlble at at that github repository  for further details, but basically I wrote a departure_timetable_function and fixed up a bit where it wasn't accounting for through-running services.  This was then directly adjusted to create an arrival_timetable function (below) --- However, I did not adjust all the variable names in the function to reflect that it is about arrivals, not departures. 
#---also, something broke in the first few lines where it adds the trip_origins to the gtfs$trips data.  Not quite sure what broke, but the first 15 lines of the below function fixes it. 

library(tidytransit)
#gtfs <- read_gtfs("data/1google_transit.zip")
#stop_to_show <- "Wallan Railway Station (Wallan)"
#date_to_show <- "2023-04-27"

arrival_timetable_function <- function(gtfs, stop_to_show, date_to_show){
  # get the id of the first stop in the trip's stop sequence

  first_stop_id <- gtfs$stop_times %>% 
    group_by(trip_id) 

  first_stop_id <- first_stop_id %>%
      filter(stop_sequence == which.min(stop_sequence)) %>%
      summarise(trip_id, stop_id)

  # join with the stops table to get the stop_name
  first_stop_names <- left_join(first_stop_id, gtfs$stops, by="stop_id")

  # rename the first stop_name as trip_origin
  trip_origins <- first_stop_names %>% select(trip_id, trip_origin = stop_name)

  # join the trip origins back onto the trips
  gtfs$trips <- left_join(gtfs$trips, trip_origins, by = "trip_id")
  
  #### get the id of the last stop in the trip's stop sequence
  last_stop_id <- gtfs$stop_times %>% 
    group_by(trip_id) %>% 
    summarise(stop_id = stop_id[which.max(stop_sequence)])

  # join with the stops table to get the stop_name
  last_stop_names <- left_join(last_stop_id, gtfs$stops, by="stop_id")

  # rename the last stop_name as trip_destination
  trip_destinations <- last_stop_names %>% dplyr::select(trip_id, trip_destination = stop_name)

  # join the trip destinations back onto the trips
  gtfs$trips <- left_join(gtfs$trips, trip_destinations, by = "trip_id")

  
  #gtfs$trips %>%
  #  dplyr::select(route_id, trip_origin) %>%
  #  head()

  if(!exists("trip_headsign", where = gtfs$trips)) {
    # get the last id of the trip's stop sequence
    trip_headsigns <- gtfs$stop_times %>% 
      group_by(trip_id) %>% 
      summarise(stop_id = stop_id[which.max(stop_sequence)]) %>% 
      left_join(gtfs$stops, by="stop_id") %>% dplyr::select(trip_id, trip_headsign.computed = stop_name)

  #create a new field with 
  trip_destination <- gtfs$stop_times %>% 
      group_by(trip_id) %>% 
      summarise(stop_id = stop_id[which.max(stop_sequence)]) %>% 
      left_join(gtfs$stops, by="stop_id") %>% dplyr::select(trip_id, trip_headsign.computed = stop_name)

    
    
    # assign the headsign to the gtfs object 
    gtfs$trips <- left_join(gtfs$trips, trip_headsigns, by = "trip_id")
  }

  stop_ids <- gtfs$stops %>% 
    filter(stop_name == stop_to_show) %>% 
    dplyr::select(stop_id)

  departures <- stop_ids %>% 
    inner_join(gtfs$stop_times %>% 
                 dplyr::select(trip_id, arrival_time, 
                        departure_time, stop_id), 
               by = "stop_id")
  
  departures <- departures %>% 
    left_join(gtfs$trips %>% 
                dplyr::select(trip_id, route_id, 
                       service_id, trip_headsign, 
                       trip_origin, 
                       trip_destination), 
              by = "trip_id") 
  
  departures <- departures %>% 
    left_join(gtfs$routes %>% 
                dplyr::select(route_id, 
                       route_short_name), 
              by = "route_id")

  #remove trips where first stop is equal to the stop_to_show, as these stops originate at this stop and so do not depart
  departures <- departures %>% 
      filter(trip_origin != stop_to_show)
  
  
  #departures %>% 
  #  dplyr::select(arrival_time,
  #         departure_time,
  #         trip_headsign,trip_origin,
  #         route_id) %>%
  #  head() %>%
  #  knitr::kable()

  #head(gtfs$.$dates_services)


  services_on_180823 <- gtfs$.$dates_services %>% 
    filter(date == date_to_show) %>% dplyr::select(service_id)

  departures_180823 <- departures %>% 
    inner_join(services_on_180823, by = "service_id")

#  departures_180823 %>%
 #   arrange(departure_time, stop_id, route_short_name) %>% 
  #  dplyr::select(departure_time, stop_id, route_short_name, trip_headsign) %>% 
   # filter(departure_time >= hms::hms(hours = 7)) %>% 
   # filter(departure_time < hms::hms(hours = 7, minutes = 10)) %>% 
  #  knitr::kable()

  route_colors <- gtfs$routes %>% dplyr::select(route_id, route_short_name, route_color)
  route_colors$route_color[which(route_colors$route_color == "")] <- "454545"
  route_colors <- setNames(paste0("#", route_colors$route_color), route_colors$route_short_name)

  #No need for list of outputs anymore, as the graphs are no longer needed
  #output <- list(
   #   ggplot(departures_180823) + theme_bw() +
    #  geom_point(aes(y=trip_origin, x=arrival_time, color = route_short_name), size = 0.2) +
     # scale_x_time(breaks = seq(0, max(as.numeric(departures$departure_time)), 3600), 
      #             labels = scales::time_format("%H:%M")) +
      #theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      #theme(legend.position = "bottom") +
      #scale_color_manual(values = route_colors) 
  #    labs(title = paste("Departures from", stop_to_show, "on", date_to_show))
  #add a return value to provide the number of services shown in the graph as an output
       #   , nrow(departures_180823)
    #  )
  #return list with graph and the number of services. 
  return(departures_180823)
  
}
#arrivals_southern_cross_230427 <- arrival_timetable_function(gtfs=mel1, stop_to_show="Southern Cross Railway Station (Melbourne City)", date_to_show="2023-04-27")
#head(arrivals_southern_cross_230427)
```

The gtfstools R package [@R-gtfstools] was used to split input GTFS feeds by mode to facilitate the buffer zone calculation. Buffer zones of 400 metres for bus and Light Rail Transit (LRT) services and 800 metres for heavy rail were adopted, as per @currie2007identifying^[There is an extended mode definition that includes modes beyond the 10 in the GTFS standard [@filter_GTFS_by_mode], but these are not dealt with by the gtfstools package. Further research may seek to extend this such that other modes can be included, but for the purposes of this study the coded buffer zone was set at 400 metres for cable trams, aerial lifts such a gondolas and trolleybuses, and at 800 metres for ferries, funiculars and monorails.].

```{r read_buffer_zone, echo=FALSE}

buffer_zone_definitions <- as_tibble(read.csv ("buffer_zones.csv"))

class(buffer_zone_definitions$code) <- "character"
buffer_zone_definitions$mode <- noquote(buffer_zone_definitions$mode)
buffer_zone_definitions$description_examples <- noquote(buffer_zone_definitions$description_examples)
class(buffer_zone_definitions$mode) <- "character"
class(buffer_zone_definitions$description_examples) <- "character"
#set buffer zone units to metres
buffer_zone_definitions$buffer <- as_units(buffer_zone_definitions$buffer, "m")

```

```{r split_gtfs_function, echo=FALSE}

split_gtfs_into_modes_and_put_in_list <- function(gtfs){ 
  gtfs_LRT <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 0))
  gtfs_subway <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 1))
  gtfs_rail <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 2))
  gtfs_bus <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 3))
  gtfs_ferry <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 4))
  gtfs_cable_tram <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 5))
  gtfs_aerial_lift <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 6))
  gtfs_funicular <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 7))
  gtfs_trolleybus <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 11))
  gtfs_monorail <- as_tidygtfs(filter_by_route_type(gtfs, route_type = 12))
 

  gtfs_into_modes_and_put_in_list <- list(
    LRT = gtfs_LRT, 
    subway = gtfs_subway,
    rail = gtfs_rail,
    bus = gtfs_bus,
    ferry = gtfs_ferry, 
    cable_tram = gtfs_cable_tram, 
    aerial_lift = gtfs_aerial_lift, 
    funicular = gtfs_funicular, 
    trolleybus = gtfs_trolleybus,
    monorail = gtfs_monorail 
  )

  return(gtfs_into_modes_and_put_in_list)
}

```

Where transit stops are located close to boundaries their catchment areas may fall into multiple areas of interest. The sp package [@R-sf] provides tools for manipulating geographic data and shape files in R. This was used to calculate the proportion of each stop's catchment area that falls into each geographical area of interest^[GTFS files define stop locations based on latitude and longitude [@GTFS], whereas the Area~Bn~ calculation needs to be provided in the same units as the Area~area~ variable, necessitating the use of a geographic transform as part of the code.].


The SI~area~ term in the SI equation was calculated on a mode-by-mode and stop-by-stop basis, by first determining the amount of the catchment area (Area~Bn~) that falls into each geographical area of interest for the stop in question. This is then combined with the area for each geographical area of interest (Area~area~) and the number of stop arrivals (SL~Bn~) to calculate the contribution to the SI scores made by just that single stop for every area of interest. These are then added to a cumulative total field for each area of interest, and the calculations are repeated until all stops and modes in the GTFS file have been included.

```{r SICCD_calc_as_functions, echo=FALSE, warning=FALSE, message=FALSE}

###Temporary variables to help with writing the function
#areas_of_interest <- sa1_map_data %>%
#  filter(gcc_name_2021 == "Greater Melbourne") 
#mel3 <- read_gtfs("data/3google_transit.zip")
#mel3_list_by_mode <- split_gtfs_into_modes_and_put_in_list(mel3)
#gtfs_list_by_mode <- mel3_list_by_mode
#start_date = "2023-04-27"
#period_in_days = 2
#EPSG_for_transform = 28355
#areas_of_interest_id_field = "sa1_code_2021"

#### The function ________
SI_calc_function <- function(areas_of_interest = areas_of_interest, areas_of_interest_id_field = areas_of_interest_id_field, gtfs_list_by_mode = gtfs_list_by_mode, start_date = start_date, period_in_days = period_in_days, EPSG_for_transform = EPSG_for_transform){

  ##Initialise variables used in function
  #the top level list. First element is a tibble of areas_of_interest_id_field. The remainder of the list has one element for each day of analysis, with each element containing a tibble with the SI scores for each mode.   
  SI_list_by_date_and_mode <- list((tibble(areas_of_interest %>% select(as.character(areas_of_interest_id_field))) %>% select(!"geometry")))
  names(SI_list_by_date_and_mode) <- as.character(areas_of_interest_id_field)

  # convert to sf format and project
  areas_of_interest_sf <- areas_of_interest %>%
  # convert to simple features
  sf::st_as_sf() %>%
    st_transform(crs = EPSG_for_transform) 
  # add Area_area value to areas_of_interest_sf 
  areas_of_interest_sf <- areas_of_interest_sf %>% 
    dplyr::mutate(Area_area = st_area(areas_of_interest_sf))
  # Add SI column to areas_of_interest_sf
  areas_of_interest_sf <- areas_of_interest_sf %>% 
    dplyr::mutate(SI = 0)
    
#2-level list to put the SI results in, with each element representing one of the days that is being analysed. 
    # This becomes a list (of lists), with one element for each mode for the day_of_analysis in question (j)
    SI_for_day_of_analysis_list_by_mode <- list()
  
  #for loop that drives the first level of the list, recording the day of analysis
  for (j in seq(1, period_in_days, 1)) {
    
    ##Initialise variables used in first level of the list
    day_of_analysis = as.character(ymd(start_date) - days(1) + days(j))
    
    #dataframe to store the SIs for each area of interest by mode for day j
       SI_for_day_of_analysis_by_mode_k <- (tibble(areas_of_interest %>% select(as.character(areas_of_interest_id_field))) %>% select(!"geometry"))
    
    ##for loop that drives the second level of the list, recording SI by mode
      for (k in seq(1, length(names(gtfs_list_by_mode)), 1)){   
        #look up the buffer distance for mode k
        buffer_distance <- buffer_zone_definitions %>% filter(short_name == as.character(names(gtfs_list_by_mode[k]))) %>% select(buffer) %>% as.numeric()
     
        #add zero-ed column to store SIs for mode k
        SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k %>% tibble::add_column(a = 0)
        #change name of added column to match mode k
names(SI_for_day_of_analysis_by_mode_k) <- c( names(SI_for_day_of_analysis_by_mode_k[,1:ncol(SI_for_day_of_analysis_by_mode_k)-1]), eval(names(gtfs_list_by_mode[k])))                         
        
        #check if the gtfs mode in question has any stops - many of the modes (e.g. Monorail) will typically have zero services or stops.  If the mode in question (k) does not have any stops, then there is no further calculation required, and the existing column of zeros can be left as is. 
        if(nrow(gtfs_list_by_mode[[as.character(names(gtfs_list_by_mode[k]))]][["stops"]]) > 0) { 
         SI_return_value_for_that_mode <- rep(0,nrow(areas_of_interest))
         #which is calculated in the following for loop, which passes over all of the stops in the gtfs file for the mode in question
          for (i in seq(1, nrow(gtfs_list_by_mode[[ as.character(names(gtfs_list_by_mode[k]))]][["stops"]]), 1)) {
      
            #create dataframe with stop i lat and lon value
            dat_sim <- data.frame(lat = gtfs_list_by_mode[[as.character(names(gtfs_list_by_mode[k]))]][["stops"]]$stop_lat[i],
            long = gtfs_list_by_mode[[as.character(names(gtfs_list_by_mode[k]))]][["stops"]]$stop_lon[i])
            # Convert that dataframe (with stop i latitude and longitude) into a sf object, with the crs set to EPSG:4326 (which is the CRS for lat/long values), 
           # and then transform to be expressed as per the EPSG that is being used for the analysis (ie. shift to metres)
            dat_sf <- st_as_sf(dat_sim, coords = c("long", "lat"), crs = 4326) %>% 
            st_transform(crs = EPSG_for_transform)
  
            # make a circle with the buffer distance as the radius around stop i    
            dat_circles <- st_buffer(dat_sf, dist = buffer_distance)
            # Intersect the circle with the polygons
            int_circles <- st_intersection(areas_of_interest_sf, dat_circles)

            ##TEST CODE Map to check that it is working the way it is expect to.
            #map <- int_circles %>%
              #ggplot() +
              #geom_sf(aes(geometry = geometry,  # use the geometry variable
                  #fill = eval(parse(text=areas_of_interest_id_field))),     # fill by SA1_code
                #lwd = 0,                  # remove borders
                #show.legend = TRUE) +    # keep legend
              #theme_void() +                    # clears other plot elements
              #coord_sf()
              
            #map

            #calculate Area Bn 
            int_circles$area_bn <- st_area(int_circles)
            
            #drop_geometry
            int_circles <- as.tibble(int_circles[, !(colnames(int_circles) %in% "geometry")])
  
            ##Retrieve number of arrivals for that mode and day by...
            #first moving the gtfs for that mode out of gtfs_list_by_mode
            gtfs_k <- as_tidygtfs(eval(parse(text = paste("gtfs_list_by_mode$",names(gtfs_list_by_mode)[k],sep = ""))))
            # then add the number of arrivals at stop i to all rows of the int_circles dataframe. 
            int_circles$SL_Bn <- rep(
              nrow(arrival_timetable_function(gtfs = gtfs_k, stop_to_show = gtfs_list_by_mode[[
                as.character(names(gtfs_list_by_mode[k]))]]$stops$stop_name[i], date_to_show = day_of_analysis)), 
              nrow(int_circles))
    
            #Calculate SI for stop i and drop units
            int_circles$add_to_SI <- as.numeric(int_circles$area_bn / int_circles$Area_area * int_circles$SL_Bn)
  
            
            #Create ordinary tibble with Area of Interest identification code and SIs from stop i to add to the running totals
            export_to_SI_for_day_of_analysis_by_mode_k <- int_circles %>% select(c(as.character(areas_of_interest_id_field), add_to_SI)) 
            
            #drop add_SI column from dataframe reporting SI_by_mode scores up to the date loop (SI_for_day_of_analysis_by_mode_k)
            SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k[, !(colnames(SI_for_day_of_analysis_by_mode_k) %in% "add_to_SI")]
  
            #merge based on eval(parse(text=areas_of_interest_id_field))
            SI_for_day_of_analysis_by_mode_k <- left_join(SI_for_day_of_analysis_by_mode_k, export_to_SI_for_day_of_analysis_by_mode_k)
  
            #convert add_to_SI to non-unit numbers
            SI_for_day_of_analysis_by_mode_k$add_to_SI <- as.vector(SI_for_day_of_analysis_by_mode_k$add_to_SI)
  
            #replace NA with 0 
            SI_for_day_of_analysis_by_mode_k[is.na(SI_for_day_of_analysis_by_mode_k)] = 0
  
            #add the SIs for stop i to the running total of SI for the mode in question
            SI_for_day_of_analysis_by_mode_k[,eval(names(gtfs_list_by_mode[k]))] <- SI_for_day_of_analysis_by_mode_k[,eval(names(gtfs_list_by_mode[k]))] + SI_for_day_of_analysis_by_mode_k$add_to_SI
          
            print(c("stop", i, "mode", k, "day", j))
            #close (i) loop for calculating SIs for stop i and adding to the running total of SI
            }
        
        #close the if(no stops in gtfs for that mode) test 
        }
       
       #close for (k) loop for calculating SI for a single mode on a single day
      }  
       
      #drop area of interest id code from dataframe of SI by mode for the day of analysis
      SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k[,2:ncol(SI_for_day_of_analysis_by_mode_k)]
      
      #drop add_to_SI column from dataframe of SI by mode for the day of analysis
      SI_for_day_of_analysis_by_mode_k <- SI_for_day_of_analysis_by_mode_k[,!names(SI_for_day_of_analysis_by_mode_k) %in% "add_to_SI"]
       
            #add new element to the list_by_date for the date_of_analysis
      SI_list_by_date_and_mode <- append(SI_list_by_date_and_mode, list(SI_for_day_of_analysis_by_mode_k), after = length(SI_list_by_date_and_mode))
    
      #update name of new element to match date
      names(SI_list_by_date_and_mode) <- c(names(SI_list_by_date_and_mode)[1:length(names(SI_list_by_date_and_mode))-1], as.character(day_of_analysis))

    #close for (j) loop for creating the list of days
    }        

 return(SI_list_by_date_and_mode)    

#close function     
}
  


#function to combine all days together. Outputs a dataframe with a row for each area_of_interest and a column for each mode
convert_SI_list_by_date_and_mode_to_SI_df_by_mode.function <- function(SI_list_by_date_and_mode = SI_list_by_date_and_mode) {
  SI_df_by_mode <- SI_list_by_date_and_mode[2:length(names(SI_list_by_date_and_mode))] %>%
  map_dfr(~setNames(.x, paste0("A", 1:ncol(.x))), .id = "Group") %>%
  group_by(Group) %>%
  mutate(ID = 1:n()) %>%
  group_by(ID) %>%
  summarize(across(-Group, .fns = sum, na.rm = TRUE)) %>%
  select(-ID)

  #update column names to match modes
  names(SI_df_by_mode) <- colnames(SI_list_by_date_and_mode[[2]])
  
  #add back area_of_interest_id_ column
  SI_df_by_mode <- cbind(SI_list_by_date_and_mode[1], SI_df_by_mode)
  
  return(SI_df_by_mode)
}



```

## Case research approach

To test the developed code and output results analysis was generated for SA1 zones within two case study areas: Clayton (SA2) and Melbourne City (SA3). Results were processed using the ggmaps [@R-ggmap], ggplot [@R-ggplot2], ggstatsplot [@R-ggstatsplot] and kable [@R-kableExtra; @R-knitr] packages, with data processing leveraging the tidyverse approach [@R-tidyverse].

### Victoria, Australia

Victoria is the southern-most state on the Australian mainland. The state capital is in Melbourne, which has a similar metropolitan area to of Paris or London^[Greater Melbourne is the term used to describe the larger metropolitan area, encompassing 30 LGAs. The City of Melbourne LGA covers only a small portion of the inner city.
]. However, with only around 5 million people Melbourne has about one-third of the population density. It has an inner Central Business District (CBD) with apartments, commercial skyscrapers and extensive sporting facilities nearby; surrounded by low-density, predominately single-family-housing-dominated, inner, middle and outer suburbs.


There are train and tram networks radiating from the CBD, but for most of the suburban areas the reality is that transit is provided by circuitious bus routes that are mostly used by those who cannot otherwise drive. An extensive freeway (and tollway) network provides connections across the Greater Melbourne area, further around Port Phillip Bay to Geelong (south-west) and the Mornington Penninsula (south-east) as well as to regional centres elsewhere in Victoria. There is a state-wide regional train and bus network (VLine), which also provides connections into South Australia, New South Wales and the Australian Capital Territory (Canberra) and local bus services in many regional towns and cities. However, accessibility to most of the city and state tends to be car-dominated. The Overland train service to Adelaide and the XPT to Sydney are provided seperately to VLine services. Victoria's GTFS feed is published by Public Transport Victoria (PTV)^[There are over 400 historical releases of the available on the transitfeeds.com website, with the first dating from March 2015 [@transitfeeds_victoria:2023aa].].

The developed code has been separately tested using SA1- and LGA-level areas of interest, including hand verification of some example SA1 areas^[This testing is reported in the main branch of the project on GitHub. This document is instead specific to the calculation of the SI scores for the 2016 SA1 boundaries.]. 

For the results reported here output was obtained for SA1-level areas using GTFS files from August 2016 and 2021, running for just the day of the census in each year. The Australian Census is undertaken in early August every 5 years. GTFS feeds were therefore selected for the first week of August of each year, with code output produced for only the day of the census itself^[It takes about a day of processing time to run the code for all of the stops in Victoria for a single 'day' of service. Hence, only the census days (rather than weeks) were analysed to speed development.]. Minor corrections were made to the GTFS files to remove duplicate stop_ids^[These involved minor discrepancies in either the stop name, latitude or longitude.].

The Australian Bureau of Statistics (ABS) provides a range of shape files and other resources. This study made use of the absmapsdata R package [@R-absmapsdata] to access the SA1 boundaries for Victoria used during the 2016 census (SA1_2016)^[Note, there is also a set of SA1 boundaries that are relevant to the 2021 census (SA1_2021).]. The EPSG:28355 transform [@EPSG_28355] was used to shift longitude and latitude into metres, as per the Geocentric Datum of Australia 1994 (GDA95 / MGA zone 55) coordinates.

```{r load_abs_data, messages = FALSE, warnings = FALSE, echo=FALSE, fig.fullwidth=TRUE, fig.cap="Melbourne SA1 map"}
#Load SA1 data
sa1_map_data <- sa12016

##Map Greater Melbourne SA1 areas
#map <- sa1_map_data %>%
#  filter(gcc_name_2021 == "Greater Melbourne") %>%   # let's just look Melbourne
#  ggplot() +
#  geom_sf(aes(geometry = geometry,  # use the geometry variable
#              fill = areasqkm_2021),     # fill by area size
#          lwd = 0,                  # remove borders
#          show.legend = TRUE) +    # keep legend
# # geom_point(aes(cent_long,
#  #               cent_lat),        # use the centroid long (x) and lats (y)
#   #          colour = "white") +    # make the points white
#  theme_void() +                    # clears other plot elements
#  coord_sf()

#map

p <- sa1_map_data
p <- p %>% 
  dplyr::mutate(area = st_area(p))
units(p$area) <- as_units("m^2")




```

```{r Melbourne_2021, echo=FALSE, warning=FALSE, message=FALSE}
###Commented out as 2021 has been precalculated
#victoria_2021 <- read_gtfs("data/Melbourne/2021/gtfs.zip")

##identify duplicate stops
#victoria_2021_duplicated_stops <- tabyl(victoria_2021$stops$stop_id) %>% filter (n>1)
#names(victoria_2021_duplicated_stops) <- c("stop_id", "n", "percent")
#victoria_2021_duplicated_stops <- left_join(victoria_2021_duplicated_stops, victoria_2021$stops)

##discard duplicates
#victoria_2021$stops <- victoria_2021$stops[!duplicated(victoria_2021$stops$stop_id),]

##split modes
#victoria_2021_list_by_mode <- split_gtfs_into_modes_and_put_in_list(victoria_2021)


##set inputs to SI_calc function
#victoria_areas_of_interest <- sa12016 %>% filter(state_name_2016 == "Victoria")
#start_date = "2021-08-10"
#period_in_days = 1
#EPSG_for_transform = 28355
#areas_of_interest_id_field = "sa1_code_2016"

##run SI_calc function
#victoria_2021_SI_list_by_date_and_mode <- SI_calc_function(areas_of_interest =  victoria_areas_of_interest, areas_of_interest_id_field = areas_of_interest_id_field, gtfs_list_by_mode = victoria_2021_list_by_mode, start_date = start_date, period_in_days = period_in_days, EPSG_for_transform = EPSG_for_transform)

##run aggregation function to create df by mode for all 7 days
#victoria_2021_SI_df_by_mode <-  convert_SI_list_by_date_and_mode_to_SI_df_by_mode.function(victoria_2021_SI_list_by_date_and_mode)

##write to csv
#write_csv2(victoria_2021_SI_df_by_mode, "~/Documents/0001_project/Transit_Supply_Index_GTFS/data/Melbourne/2021/Victoria_2021_SI_df_by_mode_SA12016_210810.csv")


#load pre-calculated df by mode (for just one day)
victoria_2021_SI_df_by_mode <- read_delim("results/Victoria_2021_SI_df_by_mode_SA12016_210810.csv", 
    delim = ";", escape_double = FALSE, col_types = cols(sa1_code_2016 = col_character(), 
        LRT = col_number(), subway = col_number(), 
        rail = col_number(), bus = col_number(), 
        ferry = col_number(), cable_tram = col_number(), 
        aerial_lift = col_number(), funicular = col_number(), 
        trolleybus = col_number(), monorail = col_number()), 
    trim_ws = TRUE)




#Join SI to map data
victoria_2021_SI_df_by_mode_sf <- left_join(victoria_2021_SI_df_by_mode, sa12016)

```

```{r Melbourne_2016, echo=FALSE, warning=FALSE, message=FALSE}
#victoria_2016 <- read_gtfs("data/Melbourne/2016/gtfs.zip")

##resolve route colour problem in gtfs file
#victoria_2016$routes$route_color <- 0

##identify duplicate stops
#victoria_2016_duplicated_stops <- tabyl(victoria_2016$stops$stop_id) %>% filter (n>1)
#names(victoria_2016_duplicated_stops) <- c("stop_id", "n", "percent")
#victoria_2016_duplicated_stops <- left_join(victoria_2016_duplicated_stops, victoria_2016$stops)

##discard duplicates
#victoria_2016$stops <- victoria_2016$stops[!duplicated(victoria_2016$stops$stop_id),]

##split modes
#victoria_2016_list_by_mode <- split_gtfs_into_modes_and_put_in_list(victoria_2016)


###set inputs to SI_calc function
#victoria_areas_of_interest <- sa1_map_data %>% filter(state_name_2016 == "Victoria")
#start_date = "2016-08-09"
#period_in_days = 1
#EPSG_for_transform = 28355
#areas_of_interest_id_field = "sa1_code_2016"

##run SI_calc function
#victoria_2016_SI_list_by_date_and_mode <- SI_calc_function(areas_of_interest =  victoria_areas_of_interest, areas_of_interest_id_field = areas_of_interest_id_field, gtfs_list_by_mode = victoria_2016_list_by_mode, start_date = start_date, period_in_days = period_in_days, EPSG_for_transform = EPSG_for_transform)

##run aggregation function to create df by mode 
#victoria_2016_SI_df_by_mode <-  convert_SI_list_by_date_and_mode_to_SI_df_by_mode.function(victoria_2016_SI_list_by_date_and_mode)

##write to csv
#write_csv2(victoria_2016_SI_df_by_mode, "~/Documents/0001_project/Transit_Supply_Index_GTFS/results/Victoria_2016_SI_df_by_mode_SA12016_160809.csv")


#load pre-calculated df by mode (for just one day)
victoria_2016_SI_df_by_mode<- read_delim("results/Victoria_2016_SI_df_by_mode_SA12016_160809.csv", 
    delim = ";", escape_double = FALSE, col_types = cols(sa1_code_2016 = col_character(), 
        LRT = col_number(), subway = col_number(), 
        rail = col_number(), bus = col_number(), 
        ferry = col_number(), cable_tram = col_number(), 
        aerial_lift = col_number(), funicular = col_number(), 
        trolleybus = col_number(), monorail = col_number()), 
    trim_ws = TRUE)

#Join map data
victoria_2016_SI_df_by_mode_sf <- left_join(victoria_2016_SI_df_by_mode, sa12016)

```

The ABS provides IRSAD datasets for SA1 in excel format. Data for 2016 and 2021 was included in this study^[The IRSAD scores for 2021 appear to only be available for the SA12021 boundaries. A correspondance file was used to match the SA12021 to SA12016 boundaries, but it was not possible to factor the scores.]. 

ISRAD Scores for 2021 are shown in Figure \ref{fig:Victoria_IRSAD_load_2021} for the Melbourne City and Clayton case study areas. 

```{r Victoria_IRSAD_load_2016, echo=FALSE, warning=FALSE, message=FALSE, fig.fullwidth = TRUE, fig.cap= "2016 IRSAD for SA1s within the Clayton SA2 boundary: score (left) and percentile within Victoria (right)", fig.show="hold", out.width="50%"}


IRSAD_2016_sa12016 <- read_excel("data/Melbourne/2016/2033055001 - sa1 indexes.xls", 
    sheet = "Table 3", skip = 4)

#Rename variables, remove rows that do not have data, change variable type to match
names(IRSAD_2016_sa12016) <- c("sa1_code_2016", "sa1_code_2016_11_digit", "usual_resident_population", "IRSAD_score","blank", "Australian_rank", "Australian_decile", "Australian_percentile", "blank2", "state_for_rank", "state_rank", "state_decile", "state_percentile")
IRSAD_2016_sa12016 <- tibble(IRSAD_2016_sa12016)
IRSAD_2016_sa12016 <- IRSAD_2016_sa12016[-1,]
IRSAD_2016_sa12016 <- head(IRSAD_2016_sa12016, -2)

IRSAD_2016_sa12016$sa1_code_2016 <- as.character(IRSAD_2016_sa12016$sa1_code_2016)
IRSAD_2016_sa12016$sa1_code_2016_11_digit <- as.character(IRSAD_2016_sa12016$sa1_code_2016_11_digit)
IRSAD_2016_sa12016$IRSAD_score <- as.numeric(IRSAD_2016_sa12016$IRSAD_score)
IRSAD_2016_sa12016$usual_resident_population <- as.numeric(IRSAD_2016_sa12016$usual_resident_population)
IRSAD_2016_sa12016$Australian_rank <- as.numeric(IRSAD_2016_sa12016$Australian_rank)
IRSAD_2016_sa12016$Australian_decile <- as.numeric(IRSAD_2016_sa12016$Australian_decile)
IRSAD_2016_sa12016$Australian_percentile <- as.numeric(IRSAD_2016_sa12016$Australian_percentile)
IRSAD_2016_sa12016$state_rank <- as.numeric(IRSAD_2016_sa12016$state_rank)
IRSAD_2016_sa12016$state_decile <- as.numeric(IRSAD_2016_sa12016$state_decile)
IRSAD_2016_sa12016$state_percentile <- as.numeric(IRSAD_2016_sa12016$state_percentile)

IRSAD_2016_sa12016_map <- left_join(IRSAD_2016_sa12016, sa1_map_data, join_by("sa1_code_2016" == "sa1_7dig_2016"))


map <- IRSAD_2016_sa12016_map %>%
  filter(sa2_name_2016 == "Clayton") %>%   
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
             fill = IRSAD_score),     # fill by IRSAD_score
          lwd = 0,                  # remove borders
         show.legend = TRUE) +   # fill colours on log scale
# geom_point(aes(cent_long,
    #           cent_lat),        # use the centroid long (x) and lats (y)
   #          colour = "white") +    # make the points white
  # theme_void() +                    # clears other plot elements
 coord_sf()

#map


map <- IRSAD_2016_sa12016_map %>%
  filter(sa2_name_2016 == "Clayton") %>%   
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
             fill = state_percentile),     # fill by IRSAD_score
          lwd = 0,                  # remove borders
         show.legend = TRUE) +   # fill colours on log scale
# geom_point(aes(cent_long,
    #           cent_lat),        # use the centroid long (x) and lats (y)
   #          colour = "white") +    # make the points white
  # theme_void() +                    # clears other plot elements
 coord_sf()

#map


```

```{r Victoria_IRSAD_load_2021, echo=FALSE, warning=FALSE, message=FALSE, fig.fullwidth = TRUE, fig.cap= "2021 IRSAD score for SA1s: within the Clayton SA2 zone (left) and within the Melbourne City SA3 zone (right)", fig.show="hold", out.width="50%"}



IRSAD_2021_sa12021 <- read_excel("data/Melbourne/2021/Statistical Area Level 1, Indexes, SEIFA 2021.xlsx", 
    sheet = "Table 3", skip = 4)

#Rename variables, remove rows that do not have data, change variable type to match
names(IRSAD_2021_sa12021) <- c("sa1_code_2021_11_digit", "usual_resident_population", "IRSAD_score","blank", "Australian_rank", "Australian_decile", "Australian_percentile", "blank2", "state_for_rank", "state_rank", "state_decile", "state_percentile")
IRSAD_2021_sa12021 <- tibble(IRSAD_2021_sa12021)
IRSAD_2021_sa12021 <- IRSAD_2021_sa12021[-1,]
IRSAD_2021_sa12021 <- head(IRSAD_2021_sa12021, -3)

IRSAD_2021_sa12021$sa1_code_2021_11_digit <- as.character(IRSAD_2021_sa12021$sa1_code_2021_11_digit)
IRSAD_2021_sa12021$IRSAD_score <- as.numeric(IRSAD_2021_sa12021$IRSAD_score)
IRSAD_2021_sa12021$usual_resident_population <- as.numeric(IRSAD_2021_sa12021$usual_resident_population)
IRSAD_2021_sa12021$Australian_rank <- as.numeric(IRSAD_2021_sa12021$Australian_rank)
IRSAD_2021_sa12021$Australian_decile <- as.numeric(IRSAD_2021_sa12021$Australian_decile)
IRSAD_2021_sa12021$Australian_percentile <- as.numeric(IRSAD_2021_sa12021$Australian_percentile)
IRSAD_2021_sa12021$state_rank <- as.numeric(IRSAD_2021_sa12021$state_rank)
IRSAD_2021_sa12021$state_decile <- as.numeric(IRSAD_2021_sa12021$state_decile)
IRSAD_2021_sa12021$state_percentile <- as.numeric(IRSAD_2021_sa12021$state_percentile)

#Use correspondence file to convert from SA12021 to SA12016
CG_SA1_2016_SA1_2021 <- read_csv("data/Melbourne/2021/CG_SA1_2016_SA1_2021.csv")
CG_SA1_2016_SA1_2021$SA1_MAINCODE_2016 <- as.character(CG_SA1_2016_SA1_2021$SA1_MAINCODE_2016)
CG_SA1_2016_SA1_2021$SA1_CODE_2021 <- as.character(CG_SA1_2016_SA1_2021$SA1_CODE_2021)
IRSAD_2021_sa12016 <- IRSAD_2021_sa12021
IRSAD_2021_sa12021 <- left_join(IRSAD_2021_sa12021, CG_SA1_2016_SA1_2021, join_by("sa1_code_2021_11_digit" == "SA1_CODE_2021"), multiple = "first")

### Something not working with the calculation to convert IRSAD score by the correspondence file Ratios. Likely because the rations are to do with actual number of people etc. Hence, just uses the SA12021 ISRAD scores directly onto the corresponding SA12016 zones
IRSAD_2021_sa12016$IRSAD_score <- IRSAD_2021_sa12021$IRSAD_score 
IRSAD_2021_sa12016$sa1_code_2016 <- IRSAD_2021_sa12021$SA1_MAINCODE_2016
names(IRSAD_2021_sa12016) <- c("sa1_code_2021_11_digit", "usual_resident_population", "IRSAD_score","blank", "Australian_rank", "Australian_decile", "Australian_percentile", "blank2", "state_for_rank", "state_rank", "state_decile", "state_percentile", "sa1_code_2016_11_digit")


IRSAD_2021_sa12016_map <- left_join(IRSAD_2021_sa12016, sa1_map_data, join_by("sa1_code_2016_11_digit" == "sa1_code_2016"))
names(IRSAD_2021_sa12016_map)[names(IRSAD_2021_sa12016_map) == 'sa1_7dig_2016'] <- 'sa1_code_2016'

map <- IRSAD_2021_sa12016_map %>%
  filter(sa2_name_2016 == "Clayton") %>%   
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
             fill = IRSAD_score),     # fill by IRSAD_score
          lwd = 0,                  # remove borders
         show.legend = TRUE) +   # fill colours on log scale
# geom_point(aes(cent_long,
    #           cent_lat),        # use the centroid long (x) and lats (y)
   #          colour = "white") +    # make the points white
  # theme_void() +                    # clears other plot elements
 coord_sf()

map


map <- IRSAD_2021_sa12016_map %>%
  filter(sa3_name_2016 == "Melbourne City") %>%   
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
             fill = IRSAD_score),     # fill by IRSAD_score
          lwd = 0,                  # remove borders
         show.legend = TRUE) +   # fill colours on log scale
# geom_point(aes(cent_long,
    #           cent_lat),        # use the centroid long (x) and lats (y)
   #          colour = "white") +    # make the points white
  # theme_void() +                    # clears other plot elements
 coord_sf()

map


```

The ISRAD scores appear to meet expectations.  In Clayton there is no score reported for the Monash University campus, Likely due to its low resident population. Higher scores are reported for SA1s to the north-east of Clayton, in the Notting Hill area. 

For the Melbourne City SA3 zone, there are no ISRAD scores reported for the various parks^[Royal Park to the north, Fitzroy Gardens and the sporting district to the east and south east, and the SA1 with the Docklands stadium in it.]. Areas with lower IRSAD scores are located in parts of North Melbourne and in the north-east ^[Lygon Street and Nicholson Street areas.], which meets expectations. 


# Results

The following subsections discuss the results of running the code for all of Victoria for 2016 and 2021, and the looks in detail at the two selected cases (Clayton and Melbourne City) as a validation of the results. 

## Supply Index results for all of Victoria

Four files are output by this document^[Located in the 'results' subdirectory of the SA12016 branch in the github repository.]. These include the total 2016 and 2021 SI scores for each SA12016 zone^[Victoria_2016_SA_SA2016_160809.csv and Victoria_2021_SI_SA12016_210810.csv], and the SI scores by mode^[Victoria_2016_SI_df_by_mode...etc.].  

```{r Victoria_SI_outputs, echo=FALSE, warning=FALSE, message=FALSE}

victoria_2016_SI_total <- victoria_2016_SI_df_by_mode %>% adorn_totals(where = "col")
##write total to csv
#write_csv2(victoria_2016_SI_total %>% select(sa1_code_2016, Total), "results/Victoria_2016_SI_SA12016_160809.csv")

#join to map data (not included in the CSV)
victoria_2016_SI_total <- left_join(victoria_2016_SI_total, sa1_map_data)


#create total column
victoria_2021_SI_total <- victoria_2021_SI_df_by_mode %>% adorn_totals(where = "col")
##write total to csv
#write_csv2(victoria_2021_SI_total %>% select(sa1_code_2016, Total), "results/Victoria_2021_SI_SA12016_210810.csv")

#join to map data (not included in the CSV)
victoria_2021_SI_total <- left_join(victoria_2021_SI_total, sa1_map_data)



```


## Verifing the code output
Code output results were verified by comparison to by-hand calculations for selected combinations of date and location in Victoria. 

### Running Creek and Morgans Bridge, Kiewa Valley Hwy
The SA1 area 20403106915 covers Running Creek and Morgans Bridge, two localities in the Victorian Alps. Within this SA1 area there are only two V/Line bus stops^[Stop:ID 45125, Running Creek Rd/Kiewa Valley Hwy (Running Creek) and Stop ID: 45124, Kiewa Valley Hwy (Mongans Bridge).].  This SA1 was selected for the purposes of verifying the code output as it is relatively easy to calculate the relevant SI values as a cross-check, because there is only one bus service and two stops to include. The location of the SA1 20403106915 is shown in the following figure. Relevant geographic statistics are shown in the following.  

![SA1 20403106915, with approximate location of Stop:ID 45125 highlighted, sources ABS and Google Maps](images/Running_creek_bus_stop.png)



```{r Running_Creek_SA1_2016, echo=FALSE, warning=FALSE, message=FALSE, fig.fullwidth = TRUE, fig.cap= "$SI_{LGA2021, 10/8/21}$", fig.show="hold", out.width="50%"}
kable(st_drop_geometry(sa1_map_data %>% filter(sa1_code_2016 == "20403106915")), caption = "SA1 zone 20403106915 geographic data")
```

The area of SA1 20403106915 is `r st_drop_geometry(sa1_map_data %>% filter(sa1_code_2016 == "20403106915"))$areasqkm_2021`km^2^.  By inspection, the entire 400m radius catchment area of both of the bus stops lie entirely within the SA1 20403106915 boundaries.

Hence the $Area_{Bn}/ Area_{SA1_Area}$ term for each of the bus stops is equal to $(\pi 400^2) / 284598000 =$ `r (pi * 400 * 400 / 284598000) %>% label_scientific(digits = 3)()`.  



Anyhow, this concludes the hand-calculation verification efforts to date. The next sections, therefore, look at the code outputs alone, with a focus on LGAs in Greater Melbourne and Victoria. 



No printed timetable has been located for the Albury - Mt Beauty via Baranduda and Tawonga South route that services these stops, but stop times are provided on the PTV website^[See https://tinyurl.com/5n83ryhy. This indicates services on April 27 to Albury at 7:25am, 9:25am and 9:30am. For April 28 there are services at 7:25am and 9:30am, but then there are no services over the weekend.  May 1 has two services (7:25am and 9:30am), May 2nd and 3rd both have three (7:25, 9:25 and 9:30am), bringing the total to 13. In the opposite direction the PTV website indicates a similar service pattern, only in the opposite direction and at 2:50pm, 4:20pm and 4:40pm. In general, this appears to be a school bus service pattern.  It is unclear, however, why some days have three services but others have only two.].  This indicates a  total of 26 arrivals to each of the two bus stops in a seven day week ^[The SL~Bn~ term.] Therefore the total $SI_{20403106915, 27/4-3/5/23}$ score is equal to $(2*(26* pi * 400 * 400 / 284598000))$ which is equal to `r (2*(26* pi * 400 * 400 / 284598000))`.  

The $SI_{20403106915, 27/4-3/5/23}$ score calculated by the developed code is shown in the following table.  
```{r Running_Creek_SI_calc_SA1_2021, echo=FALSE, warning=FALSE, message=FALSE, fig.fullwidth = TRUE, fig.cap= "$SI_{LGA2021, 10/8/21}$", fig.show="hold", out.width="50%"}


Victoria_total_SI_SA1_230427 <- read_csv("Victoria_total_SI_SA1_230427.csv")

kbl(Victoria_total_SI_SA1_230427 %>% filter(sa1_code_2021 == "20403106915"), caption = "Developed code output for SA1 20403106915, seven days starting April 27, 2023")

```

The hand-calculated $SI_{20403106915, 27/4-3/5/23}$ matches that produced by the developed code, suggesting that the developed code is providing the expected output.  

### Talbot, Avoca line
Talbot, north-west of Ballarat, provides a location where the accuracy of the developed code can be tested for both: 1) multiple modes; and 2) station/stop catchment areas spanning across multiple areas of interest.  As shown in the below figure, the Talbot township is covered by SA1 20103101708, which lies within the SA1 20103101707.   


![SA1 Location of 20103101707 and 20103101708 boundaries in relation to Talbot railway station and 800m catchment (red), and bus stops and 400m catchments (yellow), source ABS and PTV](images/Talbot.png)

The Talbot Railway station's 800m catchment area is roughly three-fifths in SA1 20103101708. A bus stop located close to the railway station has roughly three-quarters of its catchment in 20103101708. The bus stop at the Talbot Town Hall has almost its entire catchment area within 20103101708.  


The area of SA1 20103101707 is `r st_drop_geometry(sa1_map_data %>% filter(sa1_code_2021 == "20103101707"))$areasqkm_2021 %>% format(digits=3)`km^2^^[via LGA data from abs_map package.]. 

<!--For SA1 20103101708 the area is `r st_drop_geometry(sa1_map_data %>% filter(sa1_code_2021 == "20103101708"))$areasqkm_2021 %>% format(digits=3)`km^2^ -->


Hence the $Area_{Bn}/ Area_{SA120103101708}$ term for the Talbot Town Hall bus stop is approximately equal to $(\pi .4^2) / 3.05=$ `r (pi * .4 * .4 / 3.05)%>% format(digits=3)`.

<!---, while the $Area_{Bn}/ Area_{SA120103101707}$ is very close to zero.
--->For the bus stop at the Talbot Station the $Area_{Bn}/ Area_{SA120103101708}$ term is approximately equal to $3/4(\pi .4^2) / 3.05=$ `r ((3/4)*(pi * .4 * .4 / 3.05)) %>% format(digits=3)`<!---, while the $Area_{Bn}/ Area_{SA120103101707}$  term is $1/4(\pi .4^2) / 237=$ `r ((1/4)*(pi * .4 * .4 / 237)) %>% format(digits=3)`--->. For the Railway Station itself the $Area_{Bn}/ Area_{SA120103101708}$ term is approximately equal to $(3/5)(\pi .8^2) / 3.05=$ `r ((3/5)*(pi * .8 * .8 / 3.05)) %>% format(digits = 3)`<!---, while the $Area_{Bn}/ Area_{SA120103101707}$  term is $2/5(\pi .8^2) / 237=$ `r ((2/5)*(pi * .8 * .8 / 237)) %>% format(digits = 3)`--->. 

Review of the PTV website stop departures indicates that the typical service pattern appears to be: 

- Talbot Town Hall bus stop - 42 services per week^[One Vline bus service towards Maryborough on Thursdays, Fridays, Saturdays, Mondays and Tuesdays(5 per week); 3 Vline services towards Melbourne and/or Ballarat on Thursdays and Fridays, 2 on Saturdays, 1 on Sundays, 3 on Mondays and Tuesdays,  and 1 on Wednesdays (16 per week); two Vline bus serices towards Mildura on Thursdays and Fridays, 1 on Satudays and Sundays, 2 on Mondays and Tuesdays and 1 on Wednesdays (11 per week); local bus services to Ballarat on Thursdays (1), Fridays (1), Monday (1), Tuesday (1) and Wednesday(1) (5 per week); and local bus services towards Bendigo on Thursdays (1), Fridays (1), Mondays (1), Tuesdays (1) and Wednesdays (1) (5 per week).] 
  
  
- Talbot Station bus stop - 32 services per week^[One Vline bus service towards Maryborough on Thursdays, Fridays, Saturdays, Mondays and Tuesdays(5 per week); 3 Vline services towards Melbourne and/or Ballarat on Thursdays and Fridays, 2 on Saturdays, 1 on Sundays, 3 on Mondays and Tuesdays,  and 1 on Wednesdays (16 per week); and two Vline bus serices towards Mildura on Thursdays and Fridays, 1 on Satudays and Sundays, 2 on Mondays and Tuesdays and 1 on Wednesdays (11 per week)]

- Talbot Railway Station - 28 services per week^{Two services towards Maryborough every day of the week; and two services towards Melbourne every day of the week]

Therefore, the $SI_{20103101708}$ is approximately equal to: (Talbot Town Hall bus stop) 42 services per week x `r ((pi * .4 * .40 / 3.05)) %>% format(digits = 3)` = `r (42*(pi * .4 * .4 / 3.05)) %>% format(digits = 3)`; plus (Talbot Station bus stop) 32 services per week x $3/4(\pi .4^2) / 3.05=$ `r ((3/4)*(pi * .4 * .4 / 305)) %>% format(digits = 3)` = `r (32*(3/4)*(pi * .4 * .4 / 3.05)) %>% format(digits = 3)`; plus (Talbot Railway Station) 28 services per week x `r ((3/5)*(pi * .8 * .8 / 305)) %>% format(digits = 3)` = `r (28*(3/5)*(pi * .8 * .8 / 3.05)) %>% format(digits = 3)` = `r ((42*(pi * .4 * .4 / 3.05)) + (32*(3/4*(pi * .4 * .4 / 3.05))) + ((28*(3/5)*(pi * .8 * .8 / 3.05)))) %>% format(digits = 3)`


The $SI_{20403106915, 27/4-3/5/23}$ score calculated by the developed code is shown in the following table.  
```{r Talbot_calc_SA1_2021, echo=FALSE, warning=FALSE, message=FALSE, fig.fullwidth = TRUE, fig.cap= "$SI_{LGA2021, 10/8/21}$", fig.show="hold", out.width="50%"}


Victoria_total_SI_SA1_230427 <- read_csv("Victoria_total_SI_SA1_230427.csv")

kbl(Victoria_total_SI_SA1_230427 %>% filter(sa1_code_2021 == "20103101708"), caption = "Developed code output for SA1 20103101707, seven days starting April 27, 2023")

```

The hand-calculated $SI_{20103101708, 27/4-3/5/23}$ is  approximately `r (1-(((42*(pi * .4 * .4 / 3.05)) + (32*(3/4*(pi * .4 * .4 / 3.05))) + ((28*(3/5)*(pi * .8 * .8 / 3.05)))) / ((Victoria_total_SI_SA1_230427 %>% filter(sa1_code_2021 == "20103101708"))$SI_CCD))) %>% percent_format(digits = 3)()` lower than the value calculated by the SI code.  However, this appears to be sufficient to accept the result given that: 

- the overlaps of the station and stop catchment areas have been estimated based on PTV and ABS maps, rather then precisely calculated using GIS software; 
- the hand-calculated SI is based on current (August 2023) service schedules, whereas the code-calculated value is based on a GTFS file from April 27, 2023^[The online PTV timetables only go back a month or two, so any changes in the timetables between April and now could not be checked without looking directly at the GTFS files, which sort of defeats the purpose of doing the verification calculations.]; and
- Overall the SI scores vary greatly across LGAs^[Ranging between `r min(Victoria_total_SI_SA1_230427$SI_CCD) %>% format(digits=3)` and `r max(Victoria_total_SI_SA1_230427$SI_CCD) %>% format(digits=3, big.mark = ",")`.], meaning that a difference of just  `r ((((Victoria_total_SI_SA1_230427 %>% filter(sa1_code_2021 == "20103101708"))$SI_CCD)) - ((42*(pi * .4 * .4 / 3.05)) + (32*(3/4*(pi * .4 * .4 / 3.05))) + ((28*(3/5)*(pi * .8 * .8 / 3.05)))))  %>% format(digits = 3)` between the hand-calculated and code-calculated score is likely an issue of precision, rather than accuracy.  

Further verification work might involve:

- updating the code calculated values from $SI_{20103101708, 27/4-3/5/23}$ to $SI_{20103101708, now+7days}$ such that the current PTV timetables could be directly compared to the code output using the current GTFS files^[This would remove the chance that the service patterns have actually changed between April and now, although it is expected that even if there has been a change it is unlikely to have been large.]; 
- obtaining more precise $Area_{Bn} / Area_{area of interest}$ terms using GIS or similar; 
- stepping through the coding calculations one at a time to verify the intermediate calculations, and hence confirm that this disrepancy is simply a matter of precision; 
- undertaking the verification calculations for the  SA1 20103101707 area^[Unfortunately this is a large SA1 and there are other bus stops (outside of Talbot) that will contribute to the SI score.] or for some other area where hand calculations are relatively easy to perform. 




The next sections show results for SA1 zones within Clayton and within Greater Melbourne, so as to provide some context for the results and as a cross-check. 

## SA1s within the Clayton SA2 zone

```{r Clayton_SI_2016_and_2021_maps, echo=FALSE, warning=FALSE, message=FALSE, fig.fullwidth = TRUE, fig.cap= "SA1s witihn the Clayton SA2 zone: SI for 2016 (left) and 2021 (right) census days", fig.show="hold", out.width="50%"}



map <- victoria_2016_SI_total %>%
  filter(sa2_name_2016 == "Clayton") %>%   
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
             fill = Total),     # fill by TOtal SI
          lwd = 0,                  # remove borders
         show.legend = TRUE) +   # keep legend
  scale_fill_gradient2() +    # fill colours on log scale
# geom_point(aes(cent_long,
    #           cent_lat),        # use the centroid long (x) and lats (y)
   #          colour = "white") +    # make the points white
  # theme_void() +                    # clears other plot elements
 coord_sf()

map



map <- victoria_2021_SI_total %>%
  filter(sa2_name_2016 == "Clayton") %>%   
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
             fill = Total),     # fill by TOtal SI
          lwd = 0,                  # remove borders
         show.legend = TRUE) +   # keep legend
  scale_fill_gradient2() +    # fill colours on log scale
# geom_point(aes(cent_long,
    #           cent_lat),        # use the centroid long (x) and lats (y)
   #          colour = "white") +    # make the points white
  # theme_void() +                    # clears other plot elements
 coord_sf()

map


```

Figure \ref{fig:Clayton_SI_2016_and_2021_maps} shows SI scores for  


## SA1s within the Melbourne City SA3 zone




## Examining SA1s across all of Greater Melbourne and all of Victoria


# References {#references}

```{r, include=FALSE}
knitr::write_bib(file = 'packages.bib')
```

